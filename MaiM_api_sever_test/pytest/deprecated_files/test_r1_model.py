#!/usr/bin/env python3
"""
æµ‹è¯• R1 æ¨¡å‹çš„å¯ç”¨æ€§
"""

from openai import OpenAI


def test_r1_model():
    """æµ‹è¯• R1 æ¨¡å‹"""

    # SiliconFlow API é…ç½®
    api_key = "sk-esuvnjcyclavodrahnnpbinlmhdllnthnvmfstsnwwfiiimm"
    base_url = "https://api.siliconflow.cn/v1"

    print("ğŸ§ª æµ‹è¯• R1 æ¨¡å‹å¯ç”¨æ€§...")

    # åˆ›å»ºå®¢æˆ·ç«¯
    client = OpenAI(api_key=api_key, base_url=base_url)

    # æµ‹è¯•ä¸åŒçš„ R1 æ¨¡å‹å˜ä½“
    models_to_test = [
        "deepseek-ai/DeepSeek-R1",
        "Pro/deepseek-ai/DeepSeek-R1",
        "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
        "Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
    ]

    for model_id in models_to_test:
        print(f"\nğŸ“‹ æµ‹è¯•æ¨¡å‹: {model_id}")
        try:
            # ç®€å•çš„æµ‹è¯•è¯·æ±‚
            response = client.chat.completions.create(
                model=model_id,
                messages=[{"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç®€å•å›å¤ä¸€ä¸‹"}],
                max_tokens=50,
                temperature=0.3,
            )

            print(f"âœ… æ¨¡å‹ {model_id} æµ‹è¯•æˆåŠŸ!")
            print(f"ğŸ“ å›å¤: {response.choices[0].message.content}")

            # å¦‚æœæˆåŠŸï¼Œè¿”å›è¿™ä¸ªæ¨¡å‹ID
            return model_id

        except Exception as e:
            print(f"âŒ æ¨¡å‹ {model_id} æµ‹è¯•å¤±è´¥: {e}")

    return None


def test_alternative_models():
    """æµ‹è¯•æ›¿ä»£æ¨¡å‹"""

    print("\nğŸ”„ æµ‹è¯•å¯ç”¨çš„æ›¿ä»£æ¨¡å‹...")

    # SiliconFlow API é…ç½®
    api_key = "sk-esuvnjcyclavodrahnnpbinlmhdllnthnvmfstsnwwfiiimm"
    base_url = "https://api.siliconflow.cn/v1"

    client = OpenAI(api_key=api_key, base_url=base_url)

    # æµ‹è¯•ä¸€äº›å¯ç”¨çš„æ›¿ä»£æ¨¡å‹
    alternative_models = [
        "Pro/deepseek-ai/DeepSeek-V3",
        "deepseek-ai/DeepSeek-V3",
        "Qwen/Qwen3-30B-A3B",
        "Qwen/Qwen3-14B",
    ]

    successful_models = []

    for model_id in alternative_models:
        print(f"\nğŸ“‹ æµ‹è¯•æ›¿ä»£æ¨¡å‹: {model_id}")
        try:
            response = client.chat.completions.create(
                model=model_id,
                messages=[{"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç®€å•å›å¤ä¸€ä¸‹"}],
                max_tokens=50,
                temperature=0.3,
            )

            print(f"âœ… æ¨¡å‹ {model_id} æµ‹è¯•æˆåŠŸ!")
            print(f"ğŸ“ å›å¤: {response.choices[0].message.content}")
            successful_models.append(model_id)

        except Exception as e:
            print(f"âŒ æ¨¡å‹ {model_id} æµ‹è¯•å¤±è´¥: {e}")

    return successful_models


if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ” R1 æ¨¡å‹è¯Šæ–­æµ‹è¯•")
    print("=" * 60)

    # æµ‹è¯• R1 æ¨¡å‹
    working_r1_model = test_r1_model()

    if working_r1_model:
        print(f"\nğŸ‰ æ‰¾åˆ°å¯ç”¨çš„ R1 æ¨¡å‹: {working_r1_model}")
        print("ğŸ’¡ å»ºè®®å°† model_config.toml ä¸­çš„ r1 æ¨¡å‹çš„ model_identifier æ›´æ”¹ä¸º:")
        print(f'   model_identifier = "{working_r1_model}"')
    else:
        print("\nâŒ æ‰€æœ‰ R1 æ¨¡å‹éƒ½ä¸å¯ç”¨")

        # æµ‹è¯•æ›¿ä»£æ¨¡å‹
        alternatives = test_alternative_models()

        if alternatives:
            print(f"\nğŸ’¡ å¯ç”¨çš„æ›¿ä»£æ¨¡å‹: {alternatives}")
            print("ğŸ’¡ å»ºè®®å°† model_config.toml ä¸­çš„ planner æ¨¡å‹æ›´æ”¹ä¸º:")
            print(f"   model_list = ['{alternatives[0]}']")
            print("   å¹¶åœ¨ models éƒ¨åˆ†æ·»åŠ å¯¹åº”çš„é…ç½®")
        else:
            print("\nâŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹ï¼Œè¯·æ£€æŸ¥ API é…ç½®")

    print("\n" + "=" * 60)
