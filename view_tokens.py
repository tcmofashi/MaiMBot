#!/usr/bin/env python3
"""
ä¸“é—¨æŸ¥çœ‹ expressor.pkl æ–‡ä»¶ä¸­ token_counts çš„è„šæœ¬
"""

import pickle
import sys
import os

def view_token_counts(file_path):
    """æŸ¥çœ‹ expressor.pkl æ–‡ä»¶ä¸­çš„è¯æ±‡ç»Ÿè®¡"""
    if not os.path.exists(file_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return
    
    try:
        with open(file_path, 'rb') as f:
            data = pickle.load(f)
        
        print(f"ğŸ“ æ–‡ä»¶: {file_path}")
        print("=" * 60)
        
        if 'nb' not in data or 'token_counts' not in data['nb']:
            print("âŒ è¿™ä¸æ˜¯ä¸€ä¸ª expressor æ¨¡å‹æ–‡ä»¶")
            return
        
        token_counts = data['nb']['token_counts']
        candidates = data.get('candidates', {})
        
        print(f"ğŸ¯ æ‰¾åˆ° {len(token_counts)} ä¸ªé£æ ¼")
        print("=" * 60)
        
        for style_id, tokens in token_counts.items():
            style_text = candidates.get(style_id, "æœªçŸ¥é£æ ¼")
            print(f"\nğŸ“ {style_id}: {style_text}")
            print(f"ğŸ“Š è¯æ±‡æ•°é‡: {len(tokens)}")
            
            if tokens:
                # æŒ‰è¯é¢‘æ’åº
                sorted_tokens = sorted(tokens.items(), key=lambda x: x[1], reverse=True)
                
                print("ğŸ”¤ è¯æ±‡ç»Ÿè®¡ (æŒ‰é¢‘ç‡æ’åº):")
                for i, (word, count) in enumerate(sorted_tokens):
                    print(f"  {i+1:2d}. '{word}': {count}")
            else:
                print("  (æ— è¯æ±‡æ•°æ®)")
            
            print("-" * 40)
            
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")

def main():
    if len(sys.argv) != 2:
        print("ç”¨æ³•: python view_tokens.py <expressor.pklæ–‡ä»¶è·¯å¾„>")
        print("ç¤ºä¾‹: python view_tokens.py data/test_style_models/chat_001_expressor.pkl")
        return
    
    file_path = sys.argv[1]
    view_token_counts(file_path)

if __name__ == "__main__":
    main()
